# -*- coding: utf-8 -*-
"""HW5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xBGy6Q7SOn-hpKqUHorsw94SlUfPYxsA

# HW5 RAG

## 1. 請完成以下程式 (50%)

以下程式碼有許多不完整的地方，請依照原本的程式框架，補齊所有未完成的部分，請確保所有程式碼能完整執行並得到合理的回答結果。
"""

# ✅ STEP 1: 安裝需要的套件

!pip install -q sentence-transformers faiss-cpu requests

# ✅ STEP 2: 載入必要模組

from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import requests
import pandas as pd

### 非台大學生請執行以下程式碼獲取語料 ###

!gdown 1AF2g2WTtXQwb02S5EAD7aL48c9BkV1ed

### 非台大學生請執行以上程式碼獲取語料 ###

# ✅ STEP 3: 準備你的語料

docs_df = ("dcard-top100.csv")
df = pd.read_csv(docs_df)
documents = df.content.tolist()
docs_df

# ✅ STEP 4: 建立 embedding 模型與 FAISS 索引

embedding_model = SentenceTransformer("shibing624/text2vec-base-multilingual")

# 轉換為向量並正規化（便於 cosine 相似度）
doc_embeddings = embedding_model.encode(documents, normalize_embeddings=True)

# 建立向量索引
index = faiss.IndexFlatIP(doc_embeddings.shape[1])
index.add(doc_embeddings)

from google.colab import userdata
HUGGINGFACE_TOKEN = userdata.get('Hugging_face')

# 🤖 STEP 5: 呼叫 HuggingFace 模型 API

import requests
import os
HUGGINGFACE_TOKEN = os.getenv("HUGGINGFACE_TOKEN")


API_URL = "https://api-inference.huggingface.co/models/ClueAI/ChatYuan-large-v2"

headers = {"Authorization": f"Bearer {HUGGINGFACE_TOKEN}"}

# 請完成 prompt
def generate_answer(query, context_docs):
    context = "\n".join(f"- {doc[:300]}" for doc in context_docs)  # 避免太長
    prompt = f"""你是一個，請根據以下資料回答問題，若沒有相關資訊請回答「找不到答案」。

資料：{context}

問題：{query}

請用一到兩句話回答。
"""

    payload = {"inputs": prompt}
    response = requests.post(API_URL, headers=headers, json=payload, timeout=60)

    try:
        data = response.json()
        if isinstance(data, list) and "generated_text" in data[0]:
            return data[0]["generated_text"]
        elif isinstance(data, dict) and "generated_text" in data:
            return data["generated_text"]
        else:
            return f"⚠️ 無法解析模型回應：{data}"
    except Exception as e:
        return f"❌ 發生錯誤：{e}"

def search(query, top_k=3):

  query_vec = embedding_model.encode([query], normalize_embeddings=True)
  scores, indices = index.search(query_vec, top_k)
  matched_docs = [documents[i] for i in indices[0]]

  return matched_docs

# ✅ STEP 6: 使用者輸入問題，找出最相關的內容

query = "在哪裡可以看到很多草莓？"

relevant_docs = search(query, top_k=3)
answer = generate_answer(query, relevant_docs)

print("🔎 相關段落：\n", "\n---\n".join(relevant_docs)[:100])
print("\n💬 AI 回答：\n", answer)

"""## 2. 請回答以下問題 (50%)

請嘗試輸入至少 3 個問題給你的問答系統，並觀察模型回答的準確性與表現：

- 你問了哪些問題？

- 模型是否成功從語料中找到與問題相關的內容？

- 回答是否合理？是否有亂編的情況？

- 若問題無法回答，模型是否能正確回應「找不到答案」？

請根據你的觀察，簡述模型整體表現的優缺點。

"""